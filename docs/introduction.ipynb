{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 激光雷达和相机融合的必要性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面从传统SLAM领域说明激光雷达和可见光相机融合实现SLAM任务的必要性，参照论文[1]中的相关工作部分。\n",
    "\n",
    "可见光相机具有较高的角度分辨率和纹理颜色信息，因此可以通过投影模型和集束调整实现定位建图（比如ORB-SLAM）。然而它不能恢复尺度因子(单目相机无法获得场景深度)。\n",
    "\n",
    "为解决该问题，研究人员提出了使用立体相机(双目相机)、RGBD相机进行深度估计(即ORB-SLAM2)。然而当对远距离的物体进行深度估计时，由$z = \\frac{f * B}{d}$知立体相机需要较大的相机基线距离$B$才能进行准确的深度估计(否则视差d很小)，然而这在实际场景中非常受限。而由于RGBD相机基于红外结构光测距，因此RGBD相机非常容易受太阳光的影响，且只能对10m内的物体进行测距。解决SLAM建图尺度因子的另一种策略是融合相机和IMU，相机可以用来控制IMU的漂移，而IMU可以提供物体移动信息从而克服单目系统的尺度模糊性，比如Visual-Inertial Monocular SLAM (VINS)和融合了IMU和ORB-SLAM2的ORB-SLAM3。然而高端的IMU十分昂贵，消费级别的IMU只能低精度运行，并且容易受偏置、噪声和漂移的影响。\n",
    "\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"../resources/rgbd_vs_lidar_cam.png\" width=30%>\n",
    "</p>\n",
    "<h6 align=\"center\">激光雷达可见光融合与RGBD测距比较 </h6>\n",
    "\n",
    "\n",
    "激光雷达是通过主动式地激光发射、ToF原理对三维空间点进行深度估计，Lidar SLAM的先驱工作即LOAM，以及衍生出的LeGO-Loam, Livox-LOAM等等。然而激光雷达属于较慢的扫描式设备，因此角度分辨率较低，且无纹理颜色信息，因此在无显著结构特征的地点(比如隧道)容易失效。将激光雷达与可见光融合进行建图是发展趋势，比如VLOAM对激光雷达和相机进行松耦合位姿估计。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参考资料\n",
    "[1] Zhu Y , Zheng C , Yuan C , et al. CamVox: A Low-cost and Accurate Lidar-assisted Visual SLAM System[J]. 2020."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
